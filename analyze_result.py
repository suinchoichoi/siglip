import json
import argparse
from collections import defaultdict
import numpy as np
from pathlib import Path

def load_result(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        return json.load(f)

def summarize_results(result):
    print(f"\nğŸ“Š í´ë˜ìŠ¤ë³„ ì •í™•ë„ ë° í‰ê·  ì‹ ë¢°ë„")
    for cls, val in result.items():
        if cls in {"misclassified", "overall_accuracy", "overall_avg_confidence"}:
            continue
        acc = val["accuracy"]
        conf = val["avg_confidence"]
        print(f"  - {cls}: {acc:.2f}% (avg conf: {conf:.2f}%, {val['correct']}/{val['total']})")

    print(f"\nğŸ“ˆ ì „ì²´ ì •í™•ë„: {result['overall_accuracy']:.2f}%")
    print(f"ğŸ“ˆ ì „ì²´ í‰ê·  ì‹ ë¢°ë„: {result['overall_avg_confidence']:.2f}%")

def analyze_misclassifications(result):
    misclassified = result.get("misclassified", [])
    if not misclassified:
        print("\nâœ… ì˜¤ì¸ì‹ ì—†ìŒ")
        return

    print(f"\nâŒ ì´ ì˜¤ì¸ì‹ ìˆ˜: {len(misclassified)}")

    # í´ë˜ìŠ¤ë³„ ì˜¤ì¸ì‹ ë¶„ì„
    mis_map = defaultdict(lambda: defaultdict(list))
    for entry in misclassified:
        true_cls = entry["true_class"]
        pred_cls = entry["predicted_class"]
        conf = entry["confidence"]
        mis_map[true_cls][pred_cls].append(conf)

    print("\nğŸ“‰ ì˜¤ì¸ì‹ ìƒì„¸:")
    for true_cls, preds in mis_map.items():
        print(f"\nğŸ”¸ {true_cls} â†’")
        for pred_cls, confs in preds.items():
            avg_conf = np.mean(confs)
            print(f"   â†’ {pred_cls}: {len(confs)}ê°œ (avg conf: {avg_conf:.2f})")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--result", required=True, help="result_*.json íŒŒì¼ ê²½ë¡œ")
    args = parser.parse_args()

    result = load_result(args.result)
    summarize_results(result)
    analyze_misclassifications(result)